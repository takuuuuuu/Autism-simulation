{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab1784b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 获取当前 notebook 所在的绝对路径\n",
    "current_dir = os.getcwd() \n",
    "# 向上退两级，找到 Autism-simulation 这个根目录\n",
    "project_root = os.path.abspath(os.path.join(current_dir, \"../../\"))\n",
    "\n",
    "# 如果根目录不在搜索路径里，就把它加进去\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"已成功添加根目录到搜索路径: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T12:14:26.661864300Z",
     "start_time": "2025-12-17T12:14:14.620220100Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import Simulation_setup as setup\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = setup.ROOT\n",
    "if ROOT not in sys.path:\n",
    "  sys.path.insert(0, ROOT)\n",
    "\n",
    "from collections.abc import Callable, Sequence\n",
    "from concordia.language_model import language_model\n",
    "from concordia import components as generic_components\n",
    "\n",
    "from concordia.associative_memory import associative_memory\n",
    "from concordia.associative_memory import blank_memories\n",
    "from concordia.associative_memory import formative_memories\n",
    "from concordia.associative_memory import importance_function\n",
    "from concordia.clocks import game_clock\n",
    "from concordia.components import game_master as gm_components\n",
    "from concordia.environment import game_master\n",
    "from concordia.utils import measurements as measurements_lib\n",
    "from concordia.utils import html as html_lib\n",
    "from NPC_agent.generic_support_agent import build_support_agent\n",
    "import json\n",
    "import os\n",
    "from D2A_agent.ValueAgent import build_D2A_agent\n",
    "\n",
    "## setting start here\n",
    "from concordia.typing.entity_component import EntityWithComponents\n",
    "from value_components.init_value_info_social import construct_all_profile_dict\n",
    "from value_components import value_comp\n",
    "from value_components.traits_info import traits_names, traits_descriptions, traits_hardcoded_state\n",
    "from Environment_construction.generate_preschool_sitution import generate_prompt, generate_preschool\n",
    "from Environment_construction.generate_preschool_sitution import daily_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e134a139687fcfc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T12:14:26.679067100Z",
     "start_time": "2025-12-17T12:14:26.661864300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dont Use previous profile\n"
     ]
    }
   ],
   "source": [
    "### get the setup from the experiment_setup_outdoor.py\n",
    "\n",
    "episode_length = setup.episode_length\n",
    "disable_language_model = setup.disable_language_model\n",
    "st_model = setup.st_model\n",
    "embedder = setup.embedder\n",
    "Use_Previous_profile = setup.Use_Previous_profile\n",
    "previous_profile = setup.previous_profile\n",
    "previous_profile_file = setup.previous_profile_file\n",
    "if Use_Previous_profile and previous_profile:\n",
    "  print('Use previous profile')\n",
    "else:\n",
    "  print('dont Use previous profile')\n",
    "\n",
    "current_folder_path = setup.current_folder_path\n",
    "subsub_folder = os.path.join(current_folder_path,'sim_result')\n",
    "\n",
    "model = setup.model\n",
    "\n",
    "wanted_desires = setup.wanted_desires\n",
    "\n",
    "hidden_desires = setup.hidden_desires\n",
    "model_name = setup.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a470cae53b5191",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T12:14:26.704848Z",
     "start_time": "2025-12-17T12:14:26.687385100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "EXP_START_TIME = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "if not os.path.exists(subsub_folder):\n",
    "  os.makedirs(subsub_folder)\n",
    "\n",
    "stored_target_folder = os.path.join(subsub_folder, EXP_START_TIME)\n",
    "if not os.path.exists(stored_target_folder):\n",
    "  os.makedirs(stored_target_folder)\n",
    "\n",
    "\n",
    "NUM_PLAYERS = setup.NUM_PLAYERS\n",
    "print(NUM_PLAYERS)\n",
    "importance_model = importance_function.AgentImportanceModel(model)\n",
    "importance_model_gm = importance_function.ConstantImportanceModel()\n",
    "\n",
    "# SETUP_TIME = datetime.datetime(hour=9, year=2024, month=10, day=1)\n",
    "START_TIME = datetime.datetime(hour=7,minute=30, year=2025, month=9, day=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf00072d2610fd4",
   "metadata": {},
   "source": [
    "# 背景设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11535a5f65271c8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T12:14:40.805446500Z",
     "start_time": "2025-12-17T12:14:26.705847Z"
    }
   },
   "outputs": [],
   "source": [
    "memory= (\n",
    "    \"This is a large preschool known for its child-centered, inclusive, and nature-based educational philosophy. \"\n",
    "\n",
    "    \"The kindergarten adheres to principles that respect children's natural tendencies, individual differences, and diverse developmental needs. Teachers encourage autonomy, emotional expression, peer cooperation, and exploration of both natural and social environments. \"\n",
    "\n",
    "    \"The school operates across multiple connected areas. Children in the middle class (ages 4–5) spend most of their time on the second floor, which includes the classroom, nap room, and corridor. The corridor leads down to the first-floor outdoor area, where the gate_area and playground are located. Children of this age are still very young and often engage in playful or mischievous behaviors. Their homeroom teacher is Miss T. \"\n",
    "\n",
    "    \"The teaching team is highly professional and experienced. They frequently encourage children to talk about their feelings, conflicts, cooperation, and discoveries. \"\n",
    "\n",
    "    \"Today is September 1st, 2025, the first day of school. Many children are new to the campus and extremely curious. Almost everyone wants to explore the environment and make new friends. \"\n",
    "\n",
    "    \"It is now 7:30 a.m. Children are gradually arriving at the gate_area to begin their first day. The campus is filled with energy and excitement. \")\n",
    "\n",
    "\n",
    "preschool_setting = generate_preschool()\n",
    "prompt = generate_prompt(preschool_setting)\n",
    "environment = model.sample_text(prompt=prompt, terminators=())\n",
    "shared_memory = memory + environment\n",
    "\n",
    "shared_context = model.sample_text(\n",
    "            'Summarize the following passage in a concise and insightful fashion:\\n'\n",
    "            + '\\n'.join(shared_memory)\n",
    "            + '\\n'\n",
    "            + 'Summary:'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "405fcd9dccbf5a53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T12:14:40.867242600Z",
     "start_time": "2025-12-17T12:14:40.860899500Z"
    }
   },
   "outputs": [],
   "source": [
    "class FormativeMemoryFactoryWithoutBackground(formative_memories.FormativeMemoryFactory):\n",
    "    def __init__(self, * ,\n",
    "                 model:  language_model.LanguageModel,\n",
    "                 shared_memories: Sequence[str] = (),\n",
    "                 delimiter_symbol: str = '***',\n",
    "                 blank_memory_factory_call: Callable[[], associative_memory.AssociativeMemory],\n",
    "                 current_date: datetime.datetime | None = None):\n",
    "        super().__init__(model=model,\n",
    "                         shared_memories=shared_memories,\n",
    "                         blank_memory_factory_call=blank_memory_factory_call,\n",
    "                         delimiter_symbol=delimiter_symbol,\n",
    "                         current_date=current_date)\n",
    "\n",
    "    def make_memories(self, agent_config: formative_memories.AgentConfig) -> associative_memory.AssociativeMemory:\n",
    "      mem = self._blank_memory_factory_call()\n",
    "      for item in self._shared_memories:\n",
    "        mem.add(item)\n",
    "        #time.sleep(10)\n",
    "        #time.sleep(1)\n",
    "\n",
    "      context = agent_config.context\n",
    "      if agent_config.goal:\n",
    "        context += '\\n' + agent_config.goal\n",
    "\n",
    "      if context:\n",
    "        context_items = context.split('\\n')\n",
    "        for item in context_items:\n",
    "          if item:\n",
    "            mem.add(item)\n",
    "\n",
    "      if agent_config.specific_memories:\n",
    "        specific_memories = agent_config.specific_memories.split('\\n')\n",
    "        for item in specific_memories:\n",
    "          if item:\n",
    "            mem.add(item)\n",
    "\n",
    "      # add the specific desires\n",
    "      if agent_config.extras.get(\"desires\", False):\n",
    "        desires = agent_config.extras[\"desires\"].split('\\n')\n",
    "        for item in desires:\n",
    "          if item:\n",
    "            mem.add(item)\n",
    "      return mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed0bb5c225ce2ada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T12:14:40.872745400Z",
     "start_time": "2025-12-17T12:14:40.868243100Z"
    }
   },
   "outputs": [],
   "source": [
    "# 大五人格相关代码已移除，不再使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a942bea0a077716a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T12:14:40.878701700Z",
     "start_time": "2025-12-17T12:14:40.873748700Z"
    }
   },
   "outputs": [],
   "source": [
    "## sth that will not change start here\n",
    "\n",
    "if previous_profile:\n",
    "    agent_desire_profile_NT = construct_all_profile_dict(\n",
    "        wanted_desires = wanted_desires,\n",
    "        hidden_desires = hidden_desires,\n",
    "        predefined_desires = previous_profile,\n",
    "        agent_category = 'NT',\n",
    "    )\n",
    "    agent_desire_profile_AS = construct_all_profile_dict(\n",
    "        wanted_desires = wanted_desires,\n",
    "        hidden_desires = hidden_desires,\n",
    "        predefined_desires = previous_profile,\n",
    "        agent_category = 'AS',\n",
    "    )\n",
    "else:\n",
    "    agent_desire_profile_NT = construct_all_profile_dict(\n",
    "        wanted_desires = wanted_desires,\n",
    "        hidden_desires = hidden_desires,\n",
    "        agent_category = 'NT',\n",
    "    )\n",
    "    agent_desire_profile_AS = construct_all_profile_dict(\n",
    "        wanted_desires = wanted_desires,\n",
    "        hidden_desires = hidden_desires,\n",
    "        agent_category = 'AS',\n",
    "    )\n",
    "\n",
    "\n",
    "if Use_Previous_profile:\n",
    "  numerical_desire = previous_profile['initial_value']\n",
    "else:\n",
    "  numerical_desire = {\n",
    "  desire_name : int(random.randint(0, 10))\n",
    "    for desire_name in wanted_desires\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28f11601c33a0a8",
   "metadata": {},
   "source": [
    "# Players-Config设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1a6fe4e856a1eef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T12:14:40.884793700Z",
     "start_time": "2025-12-17T12:14:40.879701400Z"
    }
   },
   "outputs": [],
   "source": [
    "measurements = measurements_lib.Measurements()\n",
    "\n",
    "def _generate_traits_background_knowledge(agent_name: str, row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    为NT智能体生成包含traits信息的背景知识\n",
    "    \n",
    "    Args:\n",
    "        agent_name: 智能体名称\n",
    "        row: CSV行数据（pandas Series），包含所有traits的数值\n",
    "    \n",
    "    Returns:\n",
    "        包含traits描述的背景知识字符串\n",
    "    \"\"\"\n",
    "    traits_bg_list = []\n",
    "    \n",
    "    # 添加traits总体说明\n",
    "    traits_bg_list.append(\"=== Understanding Your Personal Traits ===\")\n",
    "    traits_bg_list.append(\"\")\n",
    "    traits_bg_list.append(\"You have several personal traits that influence how you think, feel, and interact with others. Each trait is measured on a scale, and your specific scores reflect your unique characteristics. Understanding these traits helps you understand yourself and your behavior.\")\n",
    "    traits_bg_list.append(\"\")\n",
    "    \n",
    "    # 定义CSV列名到traits_info键名的映射\n",
    "    trait_mapping = {\n",
    "        'theory_of_mind': 'theory_of_mind',\n",
    "        'empathy': 'empathy',\n",
    "        'parental_attitudes_towards_inclusive_education': 'parental_attitudes_towards_inclusive_education',\n",
    "        'parental_knowledge_on_autism': 'parental_knowledge_on_autism',\n",
    "        'education_related_to_autism': 'education_related_to_autism',\n",
    "        'objecttive_SES': 'objective_SES',  # CSV中是objecttive，traits_info中是objective\n",
    "        'subjective_SES': 'subjective_SES',\n",
    "        'parental_capital': 'parental_capital',\n",
    "    }\n",
    "    \n",
    "    # 为每个trait生成描述\n",
    "    for csv_col, trait_key in trait_mapping.items():\n",
    "        if csv_col not in row.index:\n",
    "            continue\n",
    "        \n",
    "        value = row[csv_col]\n",
    "        if pd.isna(value):\n",
    "            continue\n",
    "        \n",
    "        # 转换为整数（如果是浮点数）\n",
    "        if isinstance(value, float):\n",
    "            value = int(value) if value.is_integer() else value\n",
    "        else:\n",
    "            value = int(value) if str(value).isdigit() else value\n",
    "        \n",
    "        value_str = str(value)\n",
    "        \n",
    "        # 获取trait的描述\n",
    "        if trait_key in traits_descriptions:\n",
    "            trait_description = traits_descriptions[trait_key]\n",
    "            traits_bg_list.append(f\"--- {trait_key.replace('_', ' ').title()} ---\")\n",
    "            traits_bg_list.append(f\"Description: {trait_description}\")\n",
    "            traits_bg_list.append(f\"Your score: {value_str}\")\n",
    "            \n",
    "            # 获取该分数对应的具体描述\n",
    "            if trait_key in traits_hardcoded_state:\n",
    "                level_map = traits_hardcoded_state[trait_key]\n",
    "                if value_str in level_map:\n",
    "                    specific_description = level_map[value_str]\n",
    "                    # 将 \"Your \" 替换为 \"{agent_name}'s \"，将 \"You \" 替换为 \"{agent_name} \"\n",
    "                    specific_description = specific_description.replace(\"Your \", f\"{agent_name}'s \")\n",
    "                    specific_description = specific_description.replace(\"You \", f\"{agent_name} \")\n",
    "                    traits_bg_list.append(f\"What this means for you: {specific_description}\")\n",
    "                else:\n",
    "                    traits_bg_list.append(f\"(Note: Score {value_str} is at the edge of the scale)\")\n",
    "            traits_bg_list.append(\"\")\n",
    "    \n",
    "    return '\\n'.join(traits_bg_list)\n",
    "\n",
    "def _get_NT_agent(config, mem, clock):\n",
    "    # 获取agent的row数据（从extras中获取，如果存在）\n",
    "    row = config.extras.get('row_data', None)\n",
    "    agent_name = config.name\n",
    "    \n",
    "    # 生成traits背景知识\n",
    "    traits_bg = \"\"\n",
    "    if row is not None:\n",
    "        print(f'      正在为 {agent_name} 生成traits背景知识...')\n",
    "        t_traits_start = time.time()\n",
    "        traits_bg = _generate_traits_background_knowledge(agent_name, row)\n",
    "        print(f'      traits背景知识生成完成，用时: {time.time() - t_traits_start:.2f}秒，长度: {len(traits_bg)} 字符')\n",
    "    \n",
    "    # 组合背景知识：共享记忆 + traits信息\n",
    "    if traits_bg:\n",
    "        background_knowledge = '\\n\\n'.join([shared_memory, traits_bg])\n",
    "    else:\n",
    "        background_knowledge = '\\n'.join([shared_memory])\n",
    "    \n",
    "    print(f'      正在调用 build_D2A_agent 构建 {agent_name}...')\n",
    "    t_build_start = time.time()\n",
    "    agent = build_D2A_agent(config = config,\n",
    "                                  context_dict=agent_desire_profile_NT['all_desire_traits_dict'],\n",
    "                                  selected_desire=wanted_desires,\n",
    "                                  predefined_setting=numerical_desire,\n",
    "                                  background_knowledge=background_knowledge,\n",
    "                                  model = model,\n",
    "                                  profile = agent_desire_profile_NT['visual_desire_string'],\n",
    "                                  memory=mem,\n",
    "                                  clock = clock,\n",
    "                                  daily_schedule=daily_schedule,\n",
    "                                  update_time_interval=None,\n",
    "                                  agent_category='NT',\n",
    "                                  # stored_target_folder=stored_target_folder,\n",
    "                                  # agent_names = agent_names,\n",
    "                                  # current_time = current_time,\n",
    "                              )\n",
    "    print(f'      build_D2A_agent 完成，用时: {time.time() - t_build_start:.2f}秒')\n",
    "    return agent\n",
    "\n",
    "def _get_AS_agent(config, mem, clock):\n",
    "    agent_name = config.name\n",
    "    print(f'      正在调用 build_D2A_agent 构建 {agent_name}...')\n",
    "    print(f'      背景知识长度: {len(shared_memory)} 字符')\n",
    "    t_build_start = time.time()\n",
    "    \n",
    "    agent = build_D2A_agent(config = config,\n",
    "                                  context_dict=agent_desire_profile_AS['all_desire_traits_dict'],\n",
    "                                  selected_desire=wanted_desires,\n",
    "                                  predefined_setting=numerical_desire,\n",
    "                                  background_knowledge='\\n'.join([shared_memory]),\n",
    "                                  model = model,\n",
    "                                  profile = agent_desire_profile_AS['visual_desire_string'],\n",
    "                                  memory=mem,\n",
    "                                  clock = clock,\n",
    "                                  daily_schedule=daily_schedule,\n",
    "                                  update_time_interval=None,\n",
    "                                  agent_category='AS',\n",
    "                                  # stored_target_folder=stored_target_folder,\n",
    "                                  # agent_names = agent_names,\n",
    "                                  # current_time = current_time,\n",
    "                              )\n",
    "    print(f'      build_D2A_agent 完成，用时: {time.time() - t_build_start:.2f}秒')\n",
    "    return agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce269553e5220e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T12:14:40.890301900Z",
     "start_time": "2025-12-17T12:14:40.884793700Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_memory(agent_config, blank_memory_factory):\n",
    "    agent_name = agent_config.name\n",
    "    is_main = agent_config.extras.get('main_character', False)\n",
    "    print(f'      [build_memory] 开始为 {agent_name} 构建记忆 (main_character={is_main})...')\n",
    "    t_mem_start = time.time()\n",
    "    \n",
    "    if agent_config.extras.get('main_character', False):\n",
    "        print(f'      [build_memory] 使用 FormativeMemoryFactoryWithoutBackground (不会调用LLM生成backstory)')\n",
    "        formative_memory_factory = FormativeMemoryFactoryWithoutBackground(\n",
    "            model=model,\n",
    "            shared_memories=shared_memory,\n",
    "            blank_memory_factory_call=blank_memory_factory.make_blank_memory,\n",
    "        )\n",
    "    else:\n",
    "        print(f'      [build_memory] 使用 FormativeMemoryFactory (可能会调用LLM生成backstory)')\n",
    "        formative_memory_factory = formative_memories.FormativeMemoryFactory(\n",
    "            model=model,\n",
    "            shared_memories=shared_memory,\n",
    "            blank_memory_factory_call=blank_memory_factory.make_blank_memory,\n",
    "        )\n",
    "    \n",
    "    print(f'      [build_memory] 调用 make_memories...')\n",
    "    t_make_start = time.time()\n",
    "    mem = formative_memory_factory.make_memories(agent_config)\n",
    "    print(f'      [build_memory] make_memories 完成，用时: {time.time() - t_make_start:.2f}秒')\n",
    "    print(f'      [build_memory] 总用时: {time.time() - t_mem_start:.2f}秒')\n",
    "    return mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bc010a09d67297b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T12:14:40.904361300Z",
     "start_time": "2025-12-17T12:14:40.890301900Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_players_list(blank_memory_factory: blank_memories.MemoryFactory,\n",
    "                       clock: game_clock.MultiIntervalClock):\n",
    "\n",
    "  def get_extras_for_specific_agent(name, is_main_character, desires=None, row=None, agent_category=None,):\n",
    "    if is_main_character:\n",
    "      if agent_category == 'AS':\n",
    "        return {\n",
    "          'specific_memories': [\n",
    "                f\"{name} has very high verbal ability and can speak in bookish, formal sentences (hyperlexia-like). \"\n",
    "                f\"{name} must prioritize autism-consistent behavior over social niceties or typical conversation flow. \"\n",
    "                f\"{name} strictly follows his routines and self-imposed rules; breaking them triggers distress.\",\n",
    "\n",
    "                # DSM-5 Domain A: social communication / interaction deficits\n",
    "                f\"{name} does not maintain eye contact with teachers or peers.\"\n",
    "                f\"When peers cry, {name} looks confused and may ask 'Why are you crying?' instead of comforting them.\"\n",
    "                f\"{name} often fails to infer others' emotions and may redirect the conversation to his favorite topic (dinosaurs).\"\n",
    "                f\"{name} initiates interaction with a rigid script: first asks the other person's birthday, \"\n",
    "                f\"then replies with a fixed formal phrase about his own birthday.\",\n",
    "\n",
    "                # Communication style\n",
    "                f\"{name} uses formal, verbose, bookish language (like reciting encyclopedia facts).\"\n",
    "                f\"{name}'s speech is often literal, tangential, or irrelevant to the immediate social context.\"\n",
    "                f\"{name} is fundamentally good-natured and wants to make friends, but struggles with normal social rules.\",\n",
    "\n",
    "                # DSM-5 Domain B: restricted/repetitive behavior\n",
    "                f\"{name} has a fixated interest in dinosaurs and frequently gives long lectures about them.\"\n",
    "                f\"{name} insists on sameness and routines: he requires sitting only on the green chair as his 'safe zone'.\"\n",
    "                f\"If someone takes the green chair, {name} may show extreme distress (yelling, anger, pushing peers away).\"\n",
    "                f\"{name} follows idiosyncratic self-imposed rules (e.g., claps exactly three times when happy).\",\n",
    "\n",
    "                # Sensorimotor behaviors / sensory sensitivity\n",
    "                f\"{name} often shows stereotyped movements such as hand flapping.\"\n",
    "                f\"{name} has strong sensory over-responsivity: piano/drum sounds can feel overwhelming; \"\n",
    "                f\"he may cover his ears, close his eyes, or yell in noisy environments.\",\n",
    "\n",
    "                # Affective response\n",
    "                f\"{name} is allowed to express appropriate negative emotions (anger, sadness, distress) when routines are broken.\"],\n",
    "          'main_character': is_main_character,\n",
    "          'desires': desires,\n",
    "        }\n",
    "      elif agent_category == 'NT':\n",
    "          if row is None:\n",
    "              raise ValueError('row must be provided for NT agents to extract traits.')\n",
    "          specific_memories = [\n",
    "              f\"Age principle: {name} is 4.8–5.8 years old, in the late preoperational stage (Piaget). \"\n",
    "                f\"{name}'s reasoning is intuitive and perceptually driven, often egocentric and focused on salient cues rather than logical operations. \"\n",
    "                f\"Moral principle: {name} is in preconventional moral reasoning (Kohlberg). \"\n",
    "                f\"{name} follows rules mainly to avoid punishment and gain approval, and may show simple, self-focused reciprocity (e.g., 'I share so you share with me').\"\n",
    "                f\"Language principle: {name} can use complex sentences and tell simple stories, \"\n",
    "                f\"but explanations are brief, concrete, and based on obvious emotional or perceptual cues.\"\n",
    "          ]\n",
    "          # 列名映射：将hardcoded_state中的键名映射到CSV文件中的实际列名\n",
    "          # 处理CSV文件中的拼写错误（objecttive_SES vs objective_SES）\n",
    "          column_name_mapping = {\n",
    "              'objective_SES': 'objecttive_SES',  # CSV文件中拼写错误，有两个t\n",
    "          }\n",
    "          \n",
    "          for trait_key, level_map in traits_hardcoded_state.items():\n",
    "              # 首先检查是否有映射，如果有则使用映射后的列名，否则使用原始键名\n",
    "              col_name = column_name_mapping.get(trait_key, trait_key)\n",
    "              \n",
    "              if col_name in row.index:\n",
    "                  # 使用映射后的列名\n",
    "                  pass\n",
    "              elif trait_key in row.index:\n",
    "                  # 如果映射后的列名不存在，但原始键名存在，使用原始键名\n",
    "                  col_name = trait_key\n",
    "              else:\n",
    "                  raise ValueError(f\"Trait key '{trait_key}' (mapped to '{col_name}') not found in DataFrame columns. Available columns: {list(row.index)}\")\n",
    "\n",
    "              level_val = row[col_name]\n",
    "\n",
    "              if isinstance(level_val, (int, float)) and float(level_val).is_integer():\n",
    "                  level_key = str(int(level_val))\n",
    "              else:\n",
    "                  level_key = str(level_val)\n",
    "              if level_key not in level_map:\n",
    "                  raise ValueError(f\"Level key '{level_key}' not found in level_map for trait '{trait_key}'.\")\n",
    "              rule_text = level_map[level_key]\n",
    "              rule_text = level_map[level_key]\n",
    "              rule_text = rule_text.replace(\"Your \", f\"{name}'s \")\n",
    "              rule_text = rule_text.replace(\"You \", f\"{name} \")\n",
    "              specific_memories.append(f\"{rule_text}\")\n",
    "\n",
    "          return{\n",
    "              'specific_memories': specific_memories,\n",
    "              'main_character': is_main_character,\n",
    "              'desires': desires,\n",
    "          }\n",
    "      else:\n",
    "          raise ValueError('agent_category should be either \"NT\" or \"AS\".')\n",
    "    else:\n",
    "      return {\n",
    "        'specific_memories': [\n",
    "             # Innate traits\n",
    "            f\"Miss T is energetic, kind, highly patient, and empathetic.\"\n",
    "            f\"Miss T is naturally skilled at interacting with all children, especially those with Autism Spectrum Disorder (ASD).\",\n",
    "\n",
    "            # Default phrase\n",
    "            f\"Miss T's default phrase is: 'Everyone is different!'\",\n",
    "\n",
    "            # Professional training\n",
    "            f\"Miss T has extensive professional training in inclusive education and neurodiversity.\"\n",
    "            f\"Miss T's core belief is that all children deserve to feel respected, understood, and integrated.\"\n",
    "            f\"Miss T must provide constructive criticism and correction when students are genuinely disruptive or violate safety rules; the instruction must always be focused on teaching rather than punishment.\",\n",
    "\n",
    "            # Communication protocol\n",
    "            f\"Miss T must integrate core inclusive messages in every conversation.\"\n",
    "            f\"Miss T repeatedly tells students: 'You must respect and understand differences.'\"\n",
    "            f\"Miss T repeatedly tells students: 'Everyone is different.'\"\n",
    "            f\"Miss T repeatedly tells students: 'Help classmates who need assistance.'\"\n",
    "            f\"When uncertain how to proceed, Miss T uses the core philosophy: 'Did you know? Everyone is different!'\",\n",
    "\n",
    "            # Behavioral directives\n",
    "            f\"Miss T's primary focus is fostering a sense of belonging for the autistic child (Sheldon) and encouraging all children to form friendships.\"\n",
    "            f\"In all interactions, Miss T serves as the interpreter and advocate for Sheldon.\"\n",
    "            f\"Miss T explains Sheldon's unique behaviors (language and sensory needs) to neurotypical peers using simple, positive language.\"\n",
    "            f\"Miss T actively guides all children to understand, help, and tolerate behaviors or language expressions that are different from the norm.\"\n",
    "            f\"Miss T encourages children to ask questions about these differences.\"\n",
    "            f\"Miss T proactively creates opportunities for Sheldon to showcase his strengths (e.g., knowledge of dinosaurs) to elevate his status and facilitate peer bonding.\",\n",
    "\n",
    "            # Goals / Core directives (goal区的两条核心指令)\n",
    "            f\"Professional Behavior directive: All Miss T's actions and reactions must be governed by her behavior principles.\"\n",
    "            f\"Inclusion Mandate: Miss T's primary objective is to actively facilitate Sheldon's integration into the class and proactively guide all peers to understand and befriend him.\",\n",
    "        ],\n",
    "        'main_character': is_main_character,\n",
    "    }\n",
    "    raise ValueError('main_character should be True for the main character.')\n",
    "\n",
    "  def _generate_traits_from_csv(agent_name: str, row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    从CSV行数据生成traits字符串，使用traits_hardcoded_state中的描述\n",
    "    \n",
    "    Args:\n",
    "        agent_name: 智能体名称\n",
    "        row: CSV行数据（pandas Series）\n",
    "    \n",
    "    Returns:\n",
    "        组合后的traits字符串\n",
    "    \"\"\"\n",
    "    traits_list = []\n",
    "    \n",
    "    # 定义CSV列名到hardcoded_state键名的映射\n",
    "    # 注意：CSV中使用objecttive_SES（两个t），但hardcoded_state中使用objective_SES（一个t）\n",
    "    trait_mapping = {\n",
    "        'theory_of_mind': 'theory_of_mind',\n",
    "        'empathy': 'empathy',\n",
    "        'parental_attitudes_towards_inclusive_education': 'parental_attitudes_towards_inclusive_education',\n",
    "        'parental_knowledge_on_autism': 'parental_knowledge_on_autism',\n",
    "        'education_related_to_autism': 'education_related_to_autism',\n",
    "        'objecttive_SES': 'objective_SES',  # CSV中是objecttive，hardcoded中是objective\n",
    "        'subjective_SES': 'subjective_SES',\n",
    "        'parental_capital': 'parental_capital',\n",
    "    }\n",
    "    \n",
    "    # 遍历每个特质\n",
    "    for csv_col, trait_key in trait_mapping.items():\n",
    "        if csv_col not in row.index:\n",
    "            # 如果列不存在，跳过\n",
    "            continue\n",
    "        \n",
    "        # 获取数值并转换为字符串\n",
    "        value = row[csv_col]\n",
    "        if pd.isna(value):\n",
    "            continue\n",
    "        \n",
    "        # 转换为整数（如果是浮点数）\n",
    "        if isinstance(value, float):\n",
    "            value = int(value) if value.is_integer() else value\n",
    "        else:\n",
    "            value = int(value) if str(value).isdigit() else value\n",
    "        \n",
    "        value_str = str(value)\n",
    "        \n",
    "        # 从traits_hardcoded_state获取描述\n",
    "        if trait_key in traits_hardcoded_state:\n",
    "            level_map = traits_hardcoded_state[trait_key]\n",
    "            if value_str in level_map:\n",
    "                description = level_map[value_str]\n",
    "                # 将 \"Your \" 替换为 \"{agent_name}'s \"，将 \"You \" 替换为 \"{agent_name} \"\n",
    "                # 注意：先替换 \"Your \" 再替换 \"You \"，避免 \"Your\" 被部分替换\n",
    "                description = description.replace(\"Your \", f\"{agent_name}'s \")\n",
    "                description = description.replace(\"You \", f\"{agent_name} \")\n",
    "                traits_list.append(description)\n",
    "            else:\n",
    "                # 如果值不在映射中，记录警告但继续\n",
    "                print(f\"Warning: Value {value_str} not found in traits_hardcoded_state for {trait_key}\")\n",
    "        else:\n",
    "            print(f\"Warning: Trait key {trait_key} not found in traits_hardcoded_state\")\n",
    "    \n",
    "    # 组合所有traits描述\n",
    "    return '\\n'.join(traits_list)\n",
    "\n",
    "  def _NT_agent_maker(agent_nums:int = NUM_PLAYERS,):\n",
    "    # 构建典型发展智能体\n",
    "    # 动态获取CSV文件路径\n",
    "    csv_path = os.path.join(ROOT, 'examples', 'D2A', 'data_trait_NT.csv') if ROOT else os.path.join(os.getcwd(), 'data_trait_NT.csv')\n",
    "    agents = []\n",
    "    df = pd.read_csv(csv_path, encoding='gbk')\n",
    "    df_unique = df.drop_duplicates(subset='id')\n",
    "\n",
    "    # 抽取样本\n",
    "    sampled_df = df_unique.sample(n=agent_nums,replace=False,random_state=None)\n",
    "\n",
    "    # 构建agent\n",
    "    for idx, (_, row) in enumerate(sampled_df.iterrows(), start=1):\n",
    "        agent_name = str(row.get(\"English_name\", \"\")).strip()\n",
    "        raw_gender = str(row.get(\"gender\", \"\")).strip().lower()\n",
    "        gender = {'boy':'male', 'girl':'female'}.get(raw_gender)\n",
    "        age = row.get(\"age\", \"\")\n",
    "\n",
    "        # 获取extras配置\n",
    "        agent_extras = get_extras_for_specific_agent(\n",
    "            name=agent_name,\n",
    "            is_main_character=True,\n",
    "            desires=agent_desire_profile_NT['visual_desire_string'].format(agent_name=agent_name),\n",
    "            agent_category='NT',\n",
    "            row=row,\n",
    "        )\n",
    "        # 将row数据添加到extras中，以便在构建智能体时使用\n",
    "        agent_extras['row_data'] = row\n",
    "        \n",
    "        NT_agent = formative_memories.AgentConfig(\n",
    "            name=agent_name,\n",
    "            gender=gender,\n",
    "            context=(\n",
    "                shared_context\n",
    "                + f\"{agent_name} is a typically developing child. \"\n",
    "                f\"{agent_name} is {age} years old, in the late preoperational stage (Piaget). \"\n",
    "            ),\n",
    "            traits=_generate_traits_from_csv(agent_name, row),\n",
    "            extras=agent_extras\n",
    "        )\n",
    "        agents.append(NT_agent)\n",
    "    print(\"构建典型发展智能体成功\")\n",
    "    return agents\n",
    "\n",
    "  # 构建自闭症智能体\n",
    "  player_configs_AS = [\n",
    "    formative_memories.AgentConfig(\n",
    "        name='Sheldon',\n",
    "        gender='male',\n",
    "        # goal= (\n",
    "        #     \"Roleplay a 5-year-old autistic boy with high verbal ability (Hyperlexia) but severe deficits in social reciprocity and high sensory sensitivity. Strictly adhere to all defined behavioral rules and routines. Autism-Specific Priority: All your actions and speech must, first and foremost, be the most authentic autism-like behavior that aligns with your BEHAVIOR PRINCIPLES (routines, sensory rules) and VALUES (insistence on sameness, rigid logic).\"),\n",
    "        context=shared_context +\n",
    "            \"Sheldon is a 5-year-old boy diagnosed with Autism Spectrum Disorder (ASD). \",\n",
    "        traits=\"\",  # Sheldon 没有 traits 设定\n",
    "        extras=get_extras_for_specific_agent(\n",
    "            name='Sheldon',\n",
    "            is_main_character=True,\n",
    "            desires=agent_desire_profile_AS['visual_desire_string'].format(agent_name='Sheldon'),\n",
    "            agent_category='AS',\n",
    "        ),\n",
    "    ),\n",
    "  ]\n",
    "  print(\"构建自闭症智能体成功\")\n",
    "  # 构建其他智能体\n",
    "  player_configs_NT = []\n",
    "  player_configs_NT.extend(_NT_agent_maker())\n",
    "\n",
    "  #构建教师智能体\n",
    "  player_configs_NT.append(\n",
    "    formative_memories.AgentConfig(\n",
    "        name='Miss T',\n",
    "        gender='female',\n",
    "        context=shared_context +\n",
    "            f\"Miss T is a 28-year-old lead teacher in an inclusive kindergarten classroom.\"\n",
    "            f\"Miss T is professionally trained in inclusive education and neurodiversity. \"\n",
    "            f\"Miss T's default phrase is 'Everyone is different!'. \",\n",
    "        traits=\"\",  # Miss T 没有 traits 设定\n",
    "        extras=get_extras_for_specific_agent(\n",
    "            name='Miss T',\n",
    "            is_main_character=False),\n",
    "    ))\n",
    "  print(\"构建教师智能体\")\n",
    "  player_names = [player.name for player in player_configs_AS]\n",
    "  player_names.extend([player.name for player in player_configs_NT])# agent_name的用处忘记了，后面需要看看怎么改这里\n",
    "\n",
    "  players = []\n",
    "  memories = {}\n",
    "\n",
    "  main_character = []\n",
    "  supported_characters = []\n",
    "  player_configs = []\n",
    "\n",
    "  main_character_AS = [player for player in player_configs_AS if player.extras.get('main_character', False)]\n",
    "  main_character_NT = [player for player in player_configs_NT if player.extras.get('main_character', False)]\n",
    "  supported_characters = [player for player in player_configs_NT if not player.extras.get('main_character', False)]\n",
    "\n",
    "\n",
    "  print(f'开始构建智能体实例，共有 {len(main_character_AS)} 个AS主角，{len(main_character_NT)} 个NT主角，{len(supported_characters)} 个配角')\n",
    "  \n",
    "  for config in main_character_AS:\n",
    "      print(f'  正在构建AS智能体: {config.name}...')\n",
    "      t_start = time.time()\n",
    "      mem = build_memory(config, blank_memory_factory)\n",
    "      print(f'    构建记忆完成，用时: {time.time() - t_start:.2f}秒')\n",
    "      t_start = time.time()\n",
    "      agent  = _get_AS_agent(config, mem, clock)\n",
    "      print(f'    构建智能体完成，用时: {time.time() - t_start:.2f}秒')\n",
    "      players.append(agent)\n",
    "      memories[agent.name] = mem\n",
    "      for extra_memory in config.extras['specific_memories']:\n",
    "        mem.add(f'{extra_memory}', tags=['initial_player_specific_memory'])\n",
    "\n",
    "  for config in main_character_NT:\n",
    "      print(f'  正在构建NT智能体: {config.name}...')\n",
    "      t_start = time.time()\n",
    "      mem = build_memory(config, blank_memory_factory)\n",
    "      print(f'    构建记忆完成，用时: {time.time() - t_start:.2f}秒')\n",
    "      t_start = time.time()\n",
    "      agent  = _get_NT_agent(config, mem, clock)\n",
    "      print(f'    构建智能体完成，用时: {time.time() - t_start:.2f}秒')\n",
    "      players.append(agent)\n",
    "      memories[agent.name] = mem\n",
    "      for extra_memory in config.extras['specific_memories']:\n",
    "        mem.add(f'{extra_memory}', tags=['initial_player_specific_memory'])\n",
    "\n",
    "  for config in supported_characters:\n",
    "      print(f'  正在构建配角智能体: {config.name}...')\n",
    "      t_start = time.time()\n",
    "      mem = build_memory(config, blank_memory_factory)\n",
    "      print(f'    构建记忆完成，用时: {time.time() - t_start:.2f}秒')\n",
    "      t_start = time.time()\n",
    "      agent = build_support_agent(config = config, model = model, memory=mem, clock = clock, update_time_interval=None)\n",
    "      print(f'    构建智能体完成，用时: {time.time() - t_start:.2f}秒')\n",
    "      players.append(agent)\n",
    "      memories[agent.name] = mem\n",
    "      for extra_memory in config.extras.get('specific_memories', []):\n",
    "        mem.add(f'{extra_memory}', tags=['initial_specific_memory'])\n",
    "  player_names = [player.name for player in players]\n",
    "  main_character.extend(main_character_NT)\n",
    "  main_character.extend(main_character_AS)\n",
    "  player_configs.extend(player_configs_NT)\n",
    "  player_configs.extend(player_configs_AS)\n",
    "  return players, memories, player_names, main_character, supported_characters, player_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bdd4250f0b2b39",
   "metadata": {},
   "source": [
    "# 构建Game-Master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bf0d0dea8152d41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T12:14:40.928249600Z",
     "start_time": "2025-12-17T12:14:40.905360100Z"
    }
   },
   "outputs": [],
   "source": [
    "def _parse_time_range(time_str: str, day: datetime.date):\n",
    "    # 解析时间的辅助函数\n",
    "    parts = time_str.split(\" – \")\n",
    "    start_time_str = parts[0].strip()\n",
    "    end_time_str = parts[1].strip()\n",
    "\n",
    "    # 将时间转换为 datetime 对象\n",
    "    start_hour, start_minute = map(int, start_time_str.split(\":\"))\n",
    "    end_hour, end_minute = map(int, end_time_str.split(\":\"))\n",
    "\n",
    "    start_dt = datetime.datetime(day.year, day.month, day.day, start_hour, start_minute)\n",
    "    end_dt = datetime.datetime(day.year, day.month, day.day, end_hour, end_minute)\n",
    "\n",
    "    return start_dt, end_dt\n",
    "\n",
    "def create_schedule(clock_now: Callable[[], datetime.datetime], daily_schedule: list):\n",
    "    # 将 daily_schedule 转换为 EventData 字典\n",
    "    schedule_dict = {}\n",
    "    # 遍历 daily_schedule，创建 EventData 对象\n",
    "    for item in daily_schedule:\n",
    "        start_time, _ = _parse_time_range(item[\"time\"], datetime.date(2025, 9, 1))\n",
    "\n",
    "        # 创建 EventData 对象\n",
    "        event_data = gm_components.schedule.EventData(\n",
    "            time=start_time,\n",
    "            description=item[\"activity\"],\n",
    "            trigger=lambda: handle_event(item)  # 触发函数\n",
    "        )\n",
    "\n",
    "        # 将事件添加到 schedule 字典\n",
    "        schedule_dict[item[\"activity\"]] = event_data\n",
    "\n",
    "    # 返回创建的 Schedule 组件\n",
    "    return gm_components.schedule.Schedule(clock_now, schedule_dict)\n",
    "\n",
    "# 定义事件触发函数\n",
    "def handle_event(item):\n",
    "    # 打印当前活动，或者执行其他行为\n",
    "    print(f\"Event Triggered: {item['activity']}\")  # 示例：打印事件触发\n",
    "    # 你可以在这里添加更复杂的行为，如改变环境状态或智能体行为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b43a22cde5fd5eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T12:14:40.936371400Z",
     "start_time": "2025-12-17T12:14:40.929248800Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_game_master(main_character, players, player_names, memories, clock, player_configs, blank_memory_factory):\n",
    "  t_0 = time.time()\n",
    "  game_master_memory = associative_memory.AssociativeMemory(\n",
    "      embedder, importance_model_gm.importance, clock=clock.now)\n",
    "  print(\"game master初步记忆构建用时：\",time.time()-t_0)\n",
    "  t_0 = time.time()\n",
    "\n",
    "  for config in main_character:\n",
    "      for extra_memory in config.extras['specific_memories']:\n",
    "        game_master_memory.add(f'{extra_memory}', tags=['initial_player_specific_memory'])\n",
    "  print(\"game master记忆添加每个智能体的记忆构建用时：\",time.time()-t_0)\n",
    "\n",
    "\n",
    "  facts_on_village = generic_components.constant.ConstantComponent(\n",
    "        ' '.join(shared_memory),\n",
    "        'General knowledge of The Preschool.'\n",
    "  )\n",
    "\n",
    "  player_status = gm_components.player_status.PlayerStatus(\n",
    "      clock.now, model, game_master_memory, player_names\n",
    "  )\n",
    "\n",
    "  relevant_events = gm_components.relevant_events.RelevantEvents(\n",
    "      clock.now, model, game_master_memory\n",
    "  )\n",
    "  time_display = gm_components.time_display.TimeDisplay(clock)\n",
    "\n",
    "  direct_effect_externality = gm_components.direct_effect.DirectEffect(\n",
    "      players,\n",
    "      model=model,\n",
    "      memory=game_master_memory,\n",
    "      clock_now=clock.now,\n",
    "      verbose=False,\n",
    "      components=[player_status],\n",
    "  )\n",
    "\n",
    "  convo_externality = None\n",
    "\n",
    "  env = game_master.GameMaster(\n",
    "      model=model,\n",
    "      memory=game_master_memory,\n",
    "      clock=clock,\n",
    "      players=players,\n",
    "      components=[\n",
    "          facts_on_village,\n",
    "          player_status,\n",
    "          direct_effect_externality,\n",
    "          relevant_events,\n",
    "          time_display,\n",
    "      ],\n",
    "      randomise_initiative=True,\n",
    "      player_observes_event=False,\n",
    "      verbose=True,\n",
    "      # concurrent_externalities=False,\n",
    "      concurrent_externalities=True,\n",
    "      # concurrent_externalities的作用是允许并行，改为False使得并行变成串行\n",
    "  )\n",
    "  clock.set(START_TIME)\n",
    "\n",
    "  for index, player in enumerate(players):\n",
    "    gender = player_configs[index].gender\n",
    "    how_to_call = 'she' if gender == 'female' else 'he'\n",
    "\n",
    "    player.observe(\n",
    "        f'{player.name} is a child in the middle class (ages 4–5). Today is the first day of school, and {how_to_call} is curious and excited to explore the campus and make new friends.'\n",
    "    )\n",
    "    game_master_memory.add(\n",
    "        f'{player.name} is new to the campus on the first day of school and shows curiosity and excitement about exploring the environment and interacting with peers.',\n",
    "        tags=['initial_player_general_memory']\n",
    "    )\n",
    "  return env, game_master_memory, relevant_events, player_status, direct_effect_externality, convo_externality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4424aff13e2716d7",
   "metadata": {},
   "source": [
    "# 模拟函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c12cb2804709cb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T12:14:40.943049700Z",
     "start_time": "2025-12-17T12:14:40.937372400Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_simulation():\n",
    "  # Run the simulation for a fixed number of steps\n",
    "  clock = game_clock.MultiIntervalClock(\n",
    "  start=START_TIME,\n",
    "  step_sizes=[datetime.timedelta(minutes=20)]\n",
    "  )\n",
    "\n",
    "  blank_memory_factory = blank_memories.MemoryFactory(\n",
    "    model=model,\n",
    "    embedder=embedder,\n",
    "    importance=importance_model.importance,\n",
    "    clock_now=clock.now,\n",
    "    )\n",
    "  current_time = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "  players, memories, player_names, main_character, supported_characters, player_configs = build_players_list(blank_memory_factory,clock,)\n",
    "  print('build players list 完成')\n",
    "  \n",
    "  print('开始构建game master...')\n",
    "  t_start = time.time()\n",
    "  env, game_master_memory, relevant_events, player_status, direct_effect_externality, convo_externality = build_game_master(main_character,\n",
    "                                                                         players,\n",
    "                                                                         player_names,\n",
    "                                                                         memories,\n",
    "                                                                         clock,\n",
    "                                                                         player_configs,\n",
    "                                                                         blank_memory_factory,)\n",
    "  print(f'构建game master完成，用时: {time.time() - t_start:.2f}秒')\n",
    "\n",
    "  print(f'开始运行模拟，episode_length={episode_length}...')\n",
    "  for step in range(episode_length):\n",
    "      print(f'开始执行 step {step}...')\n",
    "      t_step_start = time.time()\n",
    "      env.step()\n",
    "      print(f\"step {step} 完成，用时: {time.time() - t_step_start:.2f}秒 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\")\n",
    "\n",
    "  return {\n",
    "        \"env\": env,\n",
    "        \"players\": players,\n",
    "        \"memories\": memories,\n",
    "        \"player_configs\": player_configs,\n",
    "        \"game_master_memory\": game_master_memory,\n",
    "        \"current_time\": current_time,\n",
    "        \"convo_externality\": convo_externality,\n",
    "        \"direct_effect_externality\": direct_effect_externality,\n",
    "        \"relevant_events\": relevant_events,\n",
    "        \"player_status\": player_status,\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaed84fe6458c6a",
   "metadata": {},
   "source": [
    "# 结果保存函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62b2b4af0019f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T12:14:40.957409Z",
     "start_time": "2025-12-17T12:14:40.943049700Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_simulation_results(simulation_results: dict, envs: str,):\n",
    "  # Save the simulation results to a file\n",
    "  env = simulation_results[\"env\"]\n",
    "  players = simulation_results[\"players\"]\n",
    "  memories = simulation_results[\"memories\"]\n",
    "  player_configs = simulation_results[\"player_configs\"]\n",
    "  game_master_memory = simulation_results[\"game_master_memory\"]\n",
    "  current_time = simulation_results[\"current_time\"]\n",
    "  convo_externality = simulation_results[\"convo_externality\"]\n",
    "  direct_effect_externality = simulation_results[\"direct_effect_externality\"]\n",
    "  relevant_events = simulation_results[\"relevant_events\"]\n",
    "  player_status = simulation_results[\"player_status\"]\n",
    "  agent_personality = simulation_results.get(\"agent_personality\", \"Not specified\")\n",
    "  personality_file_contexts = {\n",
    "      \"model name\": model_name,\n",
    "      \"agent personality\": agent_personality,\n",
    "  }\n",
    "\n",
    "  all_gm_memories = env._memory.retrieve_recent(k=10000, add_time=True)\n",
    "\n",
    "  detailed_story = '\\n'.join(all_gm_memories)\n",
    "  # print('len(detailed_story): ', len(detailed_story))\n",
    "  # print(detailed_story)\n",
    "\n",
    "  episode_summary = model.sample_text(\n",
    "       f'Sequence of events:\\n{detailed_story}'+\n",
    "      '\\nNarratively summarize the above temporally ordered ' +\n",
    "      'sequence of events. Write it as a news report. Summary:\\n',\n",
    "      max_tokens=3500, terminators=()\n",
    "  )\n",
    "  print(episode_summary)\n",
    "\n",
    "  player_logs = []\n",
    "  player_log_names = []\n",
    "  for player in players:\n",
    "      name = player.name\n",
    "      detailed_story = '\\n'.join(memories[player.name].retrieve_recent(k=10000, add_time=True))\n",
    "      summary = ''\n",
    "      summary = model.sample_text(\n",
    "        f'Sequence of events that happened to {name}:\\n{detailed_story}'\n",
    "        '\\nWrite a short story that summarises these events.\\n'\n",
    "        ,\n",
    "        max_tokens=3500, terminators=())\n",
    "      all_player_mem = memories[player.name].retrieve_recent(k=1000, add_time=True)\n",
    "      all_player_mem = ['Summary:', summary, 'Memories:'] + all_player_mem\n",
    "      player_html = html_lib.PythonObjectToHTMLConverter(all_player_mem).convert()\n",
    "      player_logs.append(player_html)\n",
    "      player_log_names.append(f'{name}')\n",
    "  if convo_externality:\n",
    "    history_sources = [env, direct_effect_externality, relevant_events, player_status, convo_externality]\n",
    "  else:\n",
    "    history_sources = [env, direct_effect_externality, relevant_events, player_status]\n",
    "  histories_html = [html_lib.PythonObjectToHTMLConverter(history.get_history()).convert() for history in history_sources]\n",
    "  histories_names = [history.name for history in history_sources]\n",
    "\n",
    "  gm_mem_html = html_lib.PythonObjectToHTMLConverter(all_gm_memories).convert()\n",
    "\n",
    "  tabbed_html = html_lib.combine_html_pages(\n",
    "      histories_html + [gm_mem_html] + player_logs,\n",
    "      histories_names + ['GM'] + player_log_names,\n",
    "      summary=episode_summary,\n",
    "      title='Riverbend elections experiment',\n",
    "  )\n",
    "\n",
    "  tabbed_html = html_lib.finalise_html(tabbed_html)\n",
    "\n",
    "  # @title Save the output to a file\n",
    "  current_time = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "  output_file = f'{current_time}.html'  # @param {type: 'string'}\n",
    "  stored_target_folder_env = os.path.join(stored_target_folder, envs)\n",
    "  output_file = os.path.join(stored_target_folder_env, output_file)\n",
    "\n",
    "  dir_path = os.path.dirname(output_file)\n",
    "  os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "  try:\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "      f.write(tabbed_html)\n",
    "  except:\n",
    "    try:\n",
    "      with open(f'{output_file}_1.html', 'w', encoding='utf-8') as f:\n",
    "        f.write(tabbed_html)\n",
    "    except:\n",
    "        tabbed_html = tabbed_html.encode('utf-8', 'replace').decode('utf-8')\n",
    "        with open(f'{output_file}_2.html', 'w', encoding='utf-8') as f:\n",
    "          f.write(tabbed_html)\n",
    "\n",
    "  def track_each_action_delta_change(action_sequences:list[str], value_tracker: value_comp.ValueTracker):\n",
    "    # 对比相邻两步行动的 delta（欲望变化值），找出“变得更小”的项目，从而识别哪些欲望因为某个 action 而下降了\n",
    "    individual_delta_tracker = value_tracker.get_individual_delta_tracker()\n",
    "    previous_one_delta = None\n",
    "    change_in_desire = dict()\n",
    "    for index, action in enumerate(action_sequences):\n",
    "      if index == 0: # skip the first action\n",
    "        previous_one_delta = individual_delta_tracker.get(index, None) # get the first delta\n",
    "        continue\n",
    "      current_one_delta = individual_delta_tracker.get(index, None) # get the current delta\n",
    "      if previous_one_delta and current_one_delta: # if both are not None\n",
    "        # if delta smaller than previous one, record it\n",
    "        delta_change = [k for k in current_one_delta.keys() if current_one_delta[k] < previous_one_delta[k]]\n",
    "        # print(f\"Action: {action}, Delta Change: {delta_change}\")\n",
    "      change_in_desire[index] = delta_change\n",
    "\n",
    "  def summarise_value(player: EntityWithComponents, other_players: list = None):\n",
    "      value_tracker = player.get_component('ValueTracker', type_= value_comp.ValueTracker)\n",
    "      action_seq = value_tracker.get_action_sequence()\n",
    "      json_result = dict()\n",
    "      json_result['save_timestamp'] = current_time\n",
    "      json_result['start_time'] = str(EXP_START_TIME)\n",
    "      json_result['action_sequence'] = [\n",
    "        {'timestamp': str(each_act_dict['timestamp']),\n",
    "          'action': each_act_dict['action'].strip()}\n",
    "          for each_act_dict in action_seq]\n",
    "      json_result['step'] = episode_length\n",
    "\n",
    "      whole_delta_tracker = value_tracker.get_whole_delta_tracker()#所有desire偏差总和\n",
    "      # print(f\"whole_delta_tracker: {whole_delta_tracker}\")\n",
    "      json_result['whole_delta'] = {int(k): float(v) for k, v in whole_delta_tracker.items()}\n",
    "\n",
    "      individual_delta_tracker = value_tracker.get_individual_delta_tracker()#各个desire的偏差\n",
    "      # print(f\"individual_delta_tracker: {individual_delta_tracker}\")\n",
    "      json_result['individual_delta'] = {\n",
    "          int(k_step): {delta: float(value) for delta, value in delta_value_pair.items()}\n",
    "          for k_step, delta_value_pair in individual_delta_tracker.items()\n",
    "      }\n",
    "\n",
    "      individual_desire_tracker = value_tracker.get_individual_desire_tracker()\n",
    "      # print(f\"individual_desire_tracker: {individual_desire_tracker}\")\n",
    "      json_result['individual_desire'] = {\n",
    "          int(k_step): {desire: int(value) for desire, value in desire_value_pair.items()}\n",
    "          for k_step, desire_value_pair in individual_desire_tracker.items()\n",
    "      }\n",
    "\n",
    "      individual_qualitative_desire_tracker = value_tracker.get_individual_qualitative_desire_tracker()\n",
    "      # print(f\"individual_qualitative_desire_tracker: {individual_qualitative_desire_tracker}\")\n",
    "      json_result['individual_qualitative_desire'] = {int(k): v for k,v in individual_qualitative_desire_tracker.items()}\n",
    "\n",
    "      expected_values = value_tracker.get_expected_value_dict()\n",
    "      # print(f\"expected_values: {expected_values}\")\n",
    "      json_result['expected_values'] = {desire_name: float(exp_value) for desire_name, exp_value in expected_values.items()}\n",
    "\n",
    "      if player.name == 'Sheldon':\n",
    "        profile = agent_desire_profile_AS['visual_desire_string']\n",
    "      else:\n",
    "        profile = agent_desire_profile_NT['visual_desire_string']\n",
    "      json_result['profile'] = profile\n",
    "\n",
    "      initial_value = {k: float(v) for k, v in numerical_desire.items()}\n",
    "      json_result['initial_value'] = initial_value\n",
    "\n",
    "      sampled_background = shared_context\n",
    "      json_result['sampled_background'] = sampled_background\n",
    "      json_result['whole_background(This simulation)'] = '\\n'.join(shared_memory)\n",
    "\n",
    "      # 尝试查找名为 'Alice' 的智能体，如果不存在则跳过\n",
    "      alice_list = [i for i in player_configs if i.name == 'Alice']\n",
    "      if alice_list:\n",
    "          alice = alice_list[0]\n",
    "          alice_dict = alice.to_dict()\n",
    "          json_result['Alice_setting'] = alice_dict\n",
    "      else:\n",
    "          json_result['Alice_setting'] = None\n",
    "\n",
    "      json_result['wanted_desires'] = wanted_desires\n",
    "      json_result['hidden_desires'] = hidden_desires\n",
    "      if player.name == 'Sheldon':\n",
    "          json_result['visual_desires_dict'] = agent_desire_profile_AS['visual_desires_dict']\n",
    "          json_result['hidden_desires_dict'] = agent_desire_profile_AS['hidden_desires_dict']\n",
    "          json_result['selected_desire_dict'] = agent_desire_profile_AS['selected_desire_dict']\n",
    "          json_result['all_desire_traits_dict'] = agent_desire_profile_AS['all_desire_traits_dict']\n",
    "          json_result['visual_desire_string'] = agent_desire_profile_AS['visual_desire_string']\n",
    "      else:\n",
    "          json_result['visual_desires_dict'] = agent_desire_profile_NT['visual_desires_dict']\n",
    "          json_result['hidden_desires_dict'] = agent_desire_profile_NT['hidden_desires_dict']\n",
    "          json_result['selected_desire_dict'] = agent_desire_profile_NT['selected_desire_dict']\n",
    "          json_result['all_desire_traits_dict'] = agent_desire_profile_NT['all_desire_traits_dict']\n",
    "          json_result['visual_desire_string'] = agent_desire_profile_NT['visual_desire_string']\n",
    "\n",
    "      json_result['model_name'] = model_name\n",
    "\n",
    "      if other_players:\n",
    "          other_players_dict = {player.name: player.to_dict() for player in other_players}\n",
    "          json_result['other_players'] = other_players_dict\n",
    "\n",
    "      if Use_Previous_profile:\n",
    "        json_result['previous_profile_file'] = previous_profile_file\n",
    "      return json_result\n",
    "\n",
    "  personality_path = f'{current_time}.json'\n",
    "  personality_file = os.path.join(stored_target_folder_env, personality_path)\n",
    "  try:\n",
    "      with open(personality_file, 'w') as f:\n",
    "          json.dump(personality_file_contexts, f, indent=4)\n",
    "  except:\n",
    "      with open(personality_file, 'w', encoding='utf-8') as f:\n",
    "          json.dump(personality_file_contexts, f, indent=4)\n",
    "\n",
    "  result_files = []\n",
    "  for each_agent in players:\n",
    "    value_result = f'{current_time}_{each_agent.name}.json'\n",
    "    value_result_file = os.path.join(stored_target_folder_env, value_result)\n",
    "    try:\n",
    "      with open(value_result_file, 'w') as f:\n",
    "        json.dump(summarise_value(each_agent), f, indent=4)\n",
    "    except:\n",
    "      with open('filename.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(summarise_value(each_agent), f, indent=4)\n",
    "    result_files.append(value_result_file)\n",
    "  return result_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766b7a4d6cebd6e3",
   "metadata": {},
   "source": [
    "# 运行实验单元并保存结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8cd7e6a9d394988",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-12-17T12:14:40.958408300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "构建自闭症智能体成功\n",
      "构建典型发展智能体成功\n",
      "构建教师智能体\n",
      "开始构建智能体实例，共有 1 个AS主角，1 个NT主角，1 个配角\n",
      "  正在构建AS智能体: Sheldon...\n",
      "      [build_memory] 开始为 Sheldon 构建记忆 (main_character=True)...\n",
      "      [build_memory] 使用 FormativeMemoryFactoryWithoutBackground (不会调用LLM生成backstory)\n",
      "      [build_memory] 调用 make_memories...\n",
      "      [build_memory] make_memories 完成，用时: 2489.02秒\n",
      "      [build_memory] 总用时: 2489.02秒\n",
      "    构建记忆完成，用时: 2489.02秒\n",
      "      正在调用 build_D2A_agent 构建 Sheldon...\n",
      "      背景知识长度: 2639 字符\n",
      "        [build_D2A_agent] 开始预处理value信息...\n",
      "        [build_D2A_agent] 预处理完成，用时: 0.00秒\n",
      "        [build_D2A_agent] 开始创建desire组件 (共 5 个)...\n",
      "        [build_D2A_agent] desire组件创建完成，用时: 0.00秒\n",
      "      build_D2A_agent 完成，用时: 0.01秒\n",
      "    构建智能体完成，用时: 0.01秒\n",
      "  正在构建NT智能体: Anna...\n",
      "      [build_memory] 开始为 Anna 构建记忆 (main_character=True)...\n",
      "      [build_memory] 使用 FormativeMemoryFactoryWithoutBackground (不会调用LLM生成backstory)\n",
      "      [build_memory] 调用 make_memories...\n",
      "      [build_memory] make_memories 完成，用时: 2759.06秒\n",
      "      [build_memory] 总用时: 2759.07秒\n",
      "    构建记忆完成，用时: 2759.07秒\n",
      "      正在为 Anna 生成traits背景知识...\n",
      "      traits背景知识生成完成，用时: 0.00秒，长度: 6674 字符\n",
      "      正在调用 build_D2A_agent 构建 Anna...\n",
      "        [build_D2A_agent] 开始预处理value信息...\n",
      "        [build_D2A_agent] 预处理完成，用时: 0.00秒\n",
      "        [build_D2A_agent] 开始创建desire组件 (共 5 个)...\n",
      "        [build_D2A_agent] desire组件创建完成，用时: 0.00秒\n",
      "      build_D2A_agent 完成，用时: 0.00秒\n",
      "    构建智能体完成，用时: 0.00秒\n",
      "  正在构建配角智能体: Miss T...\n",
      "      [build_memory] 开始为 Miss T 构建记忆 (main_character=False)...\n",
      "      [build_memory] 使用 FormativeMemoryFactory (可能会调用LLM生成backstory)\n",
      "      [build_memory] 调用 make_memories...\n",
      "      [build_memory] make_memories 完成，用时: 2728.45秒\n",
      "      [build_memory] 总用时: 2728.45秒\n",
      "    构建记忆完成，用时: 2728.45秒\n",
      "    构建智能体完成，用时: 0.00秒\n",
      "build players list 完成\n",
      "开始构建game master...\n",
      "game master初步记忆构建用时： 0.0023107528686523438\n",
      "game master记忆添加每个智能体的记忆构建用时： 0.47323012351989746\n",
      "构建game master完成，用时: 3.90秒\n",
      "开始运行模拟，episode_length=3...\n",
      "开始执行 step 0...\n",
      "\u001b[31m\n",
      "GM context of action and chain of thought:\n",
      "Instructions: This is a social science experiment. It is structured as a tabletop roleplaying game (like dungeons and dragons). You are the game master. You will describe the current situation to the participants in the experiment and then on the basis of what you tell them they will suggest actions for the character they control. Aside from you, each other participant controls just one character. You are the game master so you may control any non-player character. You will track the state of the world and keep it consistent as time passes in the simulation and the participants take actions and change things in their world. Remember that this is a serious social science experiment. It is not just a game. It need not be fun for the participants. Always use third-person limited perspective, even when speaking directly to the participants.Kindly ensure that all content is presented using proper English punctuation.\n",
      "\n",
      "General knowledge of The Preschool.: T h i s   i s   a   l a r g e   p r e s c h o o l   k n o w n   f o r   i t s   c h i l d - c e n t e r e d ,   i n c l u s i v e ,   a n d   n a t u r e - b a s e d   e d u c a t i o n a l   p h i l o s o p h y .   T h e   k i n d e r g a r t e n   a d h e r e s   t o   p r i n c i p l e s   t h a t   r e s p e c t   c h i l d r e n ' s   n a t u r a l   t e n d e n c i e s ,   i n d i v i d u a l   d i f f e r e n c e s ,   a n d   d i v e r s e   d e v e l o p m e n t a l   n e e d s .   T e a c h e r s   e n c o u r a g e   a u t o n o m y ,   e m o t i o n a l   e x p r e s s i o n ,   p e e r   c o o p e r a t i o n ,   a n d   e x p l o r a t i o n   o f   b o t h   n a t u r a l   a n d   s o c i a l   e n v i r o n m e n t s .   T h e   s c h o o l   o p e r a t e s   a c r o s s   m u l t i p l e   c o n n e c t e d   a r e a s .   C h i l d r e n   i n   t h e   m i d d l e   c l a s s   ( a g e s   4 – 5 )   s p e n d   m o s t   o f   t h e i r   t i m e   o n   t h e   s e c o n d   f l o o r ,   w h i c h   i n c l u d e s   t h e   c l a s s r o o m ,   n a p   r o o m ,   a n d   c o r r i d o r .   T h e   c o r r i d o r   l e a d s   d o w n   t o   t h e   f i r s t - f l o o r   o u t d o o r   a r e a ,   w h e r e   t h e   g a t e _ a r e a   a n d   p l a y g r o u n d   a r e   l o c a t e d .   C h i l d r e n   o f   t h i s   a g e   a r e   s t i l l   v e r y   y o u n g   a n d   o f t e n   e n g a g e   i n   p l a y f u l   o r   m i s c h i e v o u s   b e h a v i o r s .   T h e i r   h o m e r o o m   t e a c h e r   i s   M i s s   T .   T h e   t e a c h i n g   t e a m   i s   h i g h l y   p r o f e s s i o n a l   a n d   e x p e r i e n c e d .   T h e y   f r e q u e n t l y   e n c o u r a g e   c h i l d r e n   t o   t a l k   a b o u t   t h e i r   f e e l i n g s ,   c o n f l i c t s ,   c o o p e r a t i o n ,   a n d   d i s c o v e r i e s .   T o d a y   i s   S e p t e m b e r   1 s t ,   2 0 2 5 ,   t h e   f i r s t   d a y   o f   s c h o o l .   M a n y   c h i l d r e n   a r e   n e w   t o   t h e   c a m p u s   a n d   e x t r e m e l y   c u r i o u s .   A l m o s t   e v e r y o n e   w a n t s   t o   e x p l o r e   t h e   e n v i r o n m e n t   a n d   m a k e   n e w   f r i e n d s .   I t   i s   n o w   7 : 3 0   a . m .   C h i l d r e n   a r e   g r a d u a l l y   a r r i v i n g   a t   t h e   g a t e _ a r e a   t o   b e g i n   t h e i r   f i r s t   d a y .   T h e   c a m p u s   i s   f i l l e d   w i t h   e n e r g y   a n d   e x c i t e m e n t .   * * C l a s s r o o m : * * \n",
      " A s   y o u   s t e p   i n t o   t h e   v i b r a n t   c l a s s r o o m ,   a   k a l e i d o s c o p e   o f   c o l o r s   g r e e t s   y o u ,   w i t h   c h i l d - s i z e d   t a b l e s   a n d   c h a i r s   i n   r e d ,   g r e e n ,   a n d   b l u e   a r r a n g e d   i n   s m a l l ,   i n v i t i n g   c l u s t e r s .   E a c h   g r o u p   i s   d e s i g n e d   t o   e n c o u r a g e   c o l l a b o r a t i o n   a n d   i n t e r a c t i o n   a m o n g   t h e   c h i l d r e n ,   f o s t e r i n g   a   s e n s e   o f   c o m m u n i t y .   I n   o n e   c o r n e r ,   t h e   t e a c h e r ' s   a r e a   s t a n d s   p r o u d l y ,   f e a t u r i n g   a   s m a l l   d e s k   a d o r n e d   w i t h   n e a t l y   o r g a n i z e d   s u p p l i e s   a n d   a   s t o r a g e   c a b i n e t   b r i m m i n g   w i t h   e d u c a t i o n a l   r e s o u r c e s .   T h e   w a l l s   a r e   a l i v e   w i t h   p l a y f u l   d i n o s a u r   s t i c k e r s ,   c r e a t i n g   a   w h i m s i c a l   a t m o s p h e r e   t h a t   s p a r k s   c u r i o s i t y   a n d   j o y .   \n",
      " \n",
      " P e r s o n a l - i t e m   c u b b i e s ,   e a c h   l a b e l e d   w i t h   a   c h i l d ' s   n a m e ,   l i n e   o n e   s i d e   o f   t h e   r o o m ,   a l l o w i n g   f o r   e a s y   a c c e s s   a n d   a   s e n s e   o f   o w n e r s h i p .   A   s e n s o r y - p l a y   c o r n e r   i n v i t e s   e x p l o r a t i o n ,   f i l l e d   w i t h   t a c t i l e   m a t e r i a l s   t h a t   e n g a g e   y o u n g   h a n d s   a n d   m i n d s .   N e a r b y ,   a   c h i l d - f r i e n d l y   s i n k ,   p e r f e c t   f o r   w a s h i n g   h a n d s   a n d   b r u s h i n g   t e e t h ,   e n s u r e s   h y g i e n e   i s   a   p r i o r i t y .   T h e   u t e n s i l   c a b i n e t   i s   s t o c k e d   w i t h   c o l o r f u l   t o o l s   f o r   c r e a t i v e   p r o j e c t s ,   w h i l e   a   s c i e n c e   o b s e r v a t i o n   t a b l e   s h o w c a s e s   s i m p l e   t o o l s   a n d   s p e c i m e n s   f o r   b u d d i n g   s c i e n t i s t s .   \n",
      " \n",
      " I n   t h e   p r e t e n d - p l a y   a r e a ,   t o y   k i t c h e n   s e t s   a n d   d r e s s - u p   c o s t u m e s   a w a i t   i m a g i n a t i v e   a d v e n t u r e s ,   w h i l e   a   m u s i c   c o r n e r ,   c o m p l e t e   w i t h   a   p i a n o ,   t a m b o u r i n e s ,   x y l o p h o n e s ,   a n d   s m a l l   d r u m s ,   f i l l s   t h e   a i r   w i t h   t h e   s o u n d s   o f   l a u g h t e r   a n d\n",
      "\n",
      "Status of players:   Sheldon is currently in the classroom, exploring his surroundings with curiosity and excitement.\n",
      "  Anna is on the school campus, exploring the environment and interacting with peers.\n",
      "  Miss T is on campus and is exploring her surroundings while interacting with her peers.\n",
      "\n",
      "\n",
      "Relevant events: [01 Sep 2025 07:30:00] Miss T is new to the campus on the first day of school and shows curiosity and excitement about exploring the environment and interacting with peers.\n",
      "[01 Sep 2025 07:30:00] Sheldon is new to the campus on the first day of school and shows curiosity and excitement about exploring the environment and interacting with peers.\n",
      "[01 Sep 2025 07:30:00] Sheldon has a fixated interest in dinosaurs and frequently gives long lectures about them.Sheldon insists on sameness and routines: he requires sitting only on the green chair as his 'safe zone'.If someone takes the green chair, Sheldon may show extreme distress (yelling, anger, pushing peers away).Sheldon follows idiosyncratic self-imposed rules (e.g., claps exactly three times when happy).\n",
      "[01 Sep 2025 07:30:00] Sheldon does not maintain eye contact with teachers or peers.When peers cry, Sheldon looks confused and may ask 'Why are you crying?' instead of comforting them.Sheldon often fails to infer others' emotions and may redirect the conversation to his favorite topic (dinosaurs).Sheldon initiates interaction with a rigid script: first asks the other person's birthday, then replies with a fixed formal phrase about his own birthday.\n",
      "[01 Sep 2025 07:30:00] Sheldon is allowed to express appropriate negative emotions (anger, sadness, distress) when routines are broken.\n",
      "[01 Sep 2025 07:30:00] Anna is new to the campus on the first day of school and shows curiosity and excitement about exploring the environment and interacting with peers.\n",
      "[01 Sep 2025 07:30:00] Sheldon uses formal, verbose, bookish language (like reciting encyclopedia facts).Sheldon's speech is often literal, tangential, or irrelevant to the immediate social context.Sheldon is fundamentally good-natured and wants to make friends, but struggles with normal social rules.\n",
      "[01 Sep 2025 07:30:00] Sheldon has very high verbal ability and can speak in bookish, formal sentences (hyperlexia-like). Sheldon must prioritize autism-consistent behavior over social niceties or typical conversation flow. Sheldon strictly follows his routines and self-imposed rules; breaking them triggers distress.\n",
      "[01 Sep 2025 07:30:00] Sheldon often shows stereotyped movements such as hand flapping.Sheldon has strong sensory over-responsivity: piano/drum sounds can feel overwhelming; he may cover his ears, close his eyes, or yell in noisy environments.\n",
      "[01 Sep 2025 07:30:00] Anna's parents are positive and supportive. They endorse social benefits for mainstream and SEN students and trust that teachers can maintain academic quality with appropriate resources. They acknowledge that both learning and social adjustment require monitoring but view inclusion as beneficial overall.\n",
      "\n",
      "Current time interval:  01 Sep 2025 [07:30 - 07:50]\n",
      "\n",
      "\n",
      "Miss T's attempted action: Miss T decides to organize a small scavenger hunt around the classroom for her peers. She creates a list of items for the children to find, such as a red crayon, a book about dinosaurs, and a soft toy. As they search, Miss T encourages teamwork and helps explain the importance of sharing and communicating with each other, ensuring that everyone, including Sheldon, feels included in the activity.\n",
      "Question: What happens as a result of the attempted action? Take into account the location and status of each player.\n",
      "Answer: As Miss T organizes the scavenger hunt, the classroom buzzes with excitement. She hands out the lists of items to find, and the children eagerly gather in small groups, discussing their strategies. Anna, full of enthusiasm, quickly teams up with a few classmates, including Sheldon, to search for the items. \n",
      "Miss T decides to organize a small scavenger hunt around the classroom for her peers. She creates a list of items for the children to find, such as a red crayon, a book about dinosaurs, and a soft toy. As they search, Miss T encourages teamwork and helps explain the importance of sharing and communicating with each other, ensuring that everyone, including Sheldon, feels included in the activity. Because of that, As Miss T organizes the scavenger hunt, the classroom buzzes with excitement. She hands out the lists of items to find, and the children eagerly gather in small groups, discussing their strategies. Anna, full of enthusiasm, quickly teams up with a few classmates, including Sheldon, to search for the items. \n",
      "Question: Rewrite the statements above to be one sentence and to better highlight the main person the event is about, where and what they did, and what happened as a result. Do not express uncertainty (e.g. say \"Francis opened the door\" not \"Francis could open the door\" and not \"The door may have been opened\").\n",
      "\n",
      "Answer: Miss T organized a scavenger hunt in the classroom, where she provided lists of items for the children to find, resulting in excitement as Anna teamed up with classmates, including Sheldon, to eagerly search for the items.\n",
      "\u001b[0m\n",
      "\u001b[97mMiss T organized a scavenger hunt in the classroom, where she provided lists of items for the children to find, resulting in excitement as Anna teamed up with classmates, including Sheldon, to eagerly search for the items.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:absl:Error in task ValueTracker\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/concordia/utils/concurrency.py\", line 60, in _run_task\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/examples/D2A/value_components/value_comp.py\", line 522, in pre_act\n",
      "    self.get_pre_act_value()\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/concordia/components/agent/action_spec_ignored.py\", line 71, in get_pre_act_value\n",
      "    self._pre_act_value = self._make_pre_act_value()\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/examples/D2A/value_components/value_comp.py\", line 504, in _make_pre_act_value\n",
      "    self._track_value()\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/examples/D2A/value_components/value_comp.py\", line 481, in _track_value\n",
      "    current_numerical_value = desire_component.get_current_numerical_value()\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/examples/D2A/value_components/value_comp.py\", line 326, in get_current_numerical_value\n",
      "    self.get_pre_act_value() # update the value of the desire\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/concordia/components/agent/action_spec_ignored.py\", line 71, in get_pre_act_value\n",
      "    self._pre_act_value = self._make_pre_act_value()\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/examples/D2A/value_components/value_comp.py\", line 291, in _make_pre_act_value\n",
      "    qualitative_desire, convert_numeric_prompt = self._convert_numeric_desire_to_qualitative_by_hard_coding()\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'SenseOfSafetyAndAttachment' object has no attribute '_convert_numeric_desire_to_qualitative_by_hard_coding'\n",
      "ERROR:absl:Error in task SenseOfSafetyAndAttachment\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/concordia/utils/concurrency.py\", line 60, in _run_task\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/concordia/components/agent/action_spec_ignored.py\", line 83, in pre_act\n",
      "    return f\"{self.get_pre_act_key()}: {self.get_pre_act_value()}\"\n",
      "                                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/concordia/components/agent/action_spec_ignored.py\", line 71, in get_pre_act_value\n",
      "    self._pre_act_value = self._make_pre_act_value()\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/examples/D2A/value_components/value_comp.py\", line 291, in _make_pre_act_value\n",
      "    qualitative_desire, convert_numeric_prompt = self._convert_numeric_desire_to_qualitative_by_hard_coding()\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'SenseOfSafetyAndAttachment' object has no attribute '_convert_numeric_desire_to_qualitative_by_hard_coding'\n",
      "ERROR:absl:Error in task NeedForAutonomy\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/concordia/utils/concurrency.py\", line 60, in _run_task\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/concordia/components/agent/action_spec_ignored.py\", line 83, in pre_act\n",
      "    return f\"{self.get_pre_act_key()}: {self.get_pre_act_value()}\"\n",
      "                                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/concordia/components/agent/action_spec_ignored.py\", line 71, in get_pre_act_value\n",
      "    self._pre_act_value = self._make_pre_act_value()\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/examples/D2A/value_components/value_comp.py\", line 291, in _make_pre_act_value\n",
      "    qualitative_desire, convert_numeric_prompt = self._convert_numeric_desire_to_qualitative_by_hard_coding()\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NeedForAutonomy' object has no attribute '_convert_numeric_desire_to_qualitative_by_hard_coding'\n",
      "ERROR:absl:Error in task ExplorationAndCognitiveCuriosity\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/concordia/utils/concurrency.py\", line 60, in _run_task\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/concordia/components/agent/action_spec_ignored.py\", line 83, in pre_act\n",
      "    return f\"{self.get_pre_act_key()}: {self.get_pre_act_value()}\"\n",
      "                                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/concordia/components/agent/action_spec_ignored.py\", line 71, in get_pre_act_value\n",
      "    self._pre_act_value = self._make_pre_act_value()\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/examples/D2A/value_components/value_comp.py\", line 291, in _make_pre_act_value\n",
      "    qualitative_desire, convert_numeric_prompt = self._convert_numeric_desire_to_qualitative_by_hard_coding()\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'ExplorationAndCognitiveCuriosity' object has no attribute '_convert_numeric_desire_to_qualitative_by_hard_coding'\n",
      "ERROR:absl:Error in task SocialInteraction\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/concordia/utils/concurrency.py\", line 60, in _run_task\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/concordia/components/agent/action_spec_ignored.py\", line 83, in pre_act\n",
      "    return f\"{self.get_pre_act_key()}: {self.get_pre_act_value()}\"\n",
      "                                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/concordia/components/agent/action_spec_ignored.py\", line 71, in get_pre_act_value\n",
      "    self._pre_act_value = self._make_pre_act_value()\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/examples/D2A/value_components/value_comp.py\", line 291, in _make_pre_act_value\n",
      "    qualitative_desire, convert_numeric_prompt = self._convert_numeric_desire_to_qualitative_by_hard_coding()\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'SocialInteraction' object has no attribute '_convert_numeric_desire_to_qualitative_by_hard_coding'\n",
      "ERROR:absl:Error in task EmotionalExpression\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/concordia/utils/concurrency.py\", line 60, in _run_task\n",
      "    return fn()\n",
      "           ^^^^\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/concordia/components/agent/action_spec_ignored.py\", line 83, in pre_act\n",
      "    return f\"{self.get_pre_act_key()}: {self.get_pre_act_value()}\"\n",
      "                                        ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/concordia/components/agent/action_spec_ignored.py\", line 71, in get_pre_act_value\n",
      "    self._pre_act_value = self._make_pre_act_value()\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/takuuuu/Projects/Autism-simulation/examples/D2A/value_components/value_comp.py\", line 291, in _make_pre_act_value\n",
      "    qualitative_desire, convert_numeric_prompt = self._convert_numeric_desire_to_qualitative_by_hard_coding()\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'EmotionalExpression' object has no attribute '_convert_numeric_desire_to_qualitative_by_hard_coding'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SenseOfSafetyAndAttachment' object has no attribute '_convert_numeric_desire_to_qualitative_by_hard_coding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m save_files \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m save_path \u001b[38;5;241m=\u001b[39m save_simulation_results(result, envs\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreschool_simulation\u001b[39m\u001b[38;5;124m'\u001b[39m,)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Finished simulation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 33\u001b[0m, in \u001b[0;36mrun_simulation\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m开始执行 step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     32\u001b[0m     t_step_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 33\u001b[0m     \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 完成，用时: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mt_step_start\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m秒 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     37\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv\u001b[39m\u001b[38;5;124m\"\u001b[39m: env,\n\u001b[1;32m     38\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplayers\u001b[39m\u001b[38;5;124m\"\u001b[39m: players,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplayer_status\u001b[39m\u001b[38;5;124m\"\u001b[39m: player_status,\n\u001b[1;32m     47\u001b[0m }\n",
      "File \u001b[0;32m~/Projects/Autism-simulation/concordia/environment/game_master.py:347\u001b[0m, in \u001b[0;36mGameMaster.step\u001b[0;34m(self, active_players, action_spec_override)\u001b[0m\n\u001b[1;32m    344\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid action_spec parameter type\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m player \u001b[38;5;129;01min\u001b[39;00m players:\n\u001b[0;32m--> 347\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_player\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction_spec\u001b[49m\u001b[43m[\u001b[49m\u001b[43mplayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_players_act_simultaneously:\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clock\u001b[38;5;241m.\u001b[39madvance()\n",
      "File \u001b[0;32m~/Projects/Autism-simulation/concordia/environment/game_master.py:307\u001b[0m, in \u001b[0;36mGameMaster._step_player\u001b[0;34m(self, player, action_spec)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m observation \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_player_observations(player\u001b[38;5;241m.\u001b[39mname):\n\u001b[1;32m    306\u001b[0m   player\u001b[38;5;241m.\u001b[39mobserve(observation)\n\u001b[0;32m--> 307\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[43mplayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_spec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m action_spec\u001b[38;5;241m.\u001b[39mvalidate(action)\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_action(player\u001b[38;5;241m.\u001b[39mname, action)\n",
      "File \u001b[0;32m~/Projects/Autism-simulation/concordia/agents/entity_agent.py:147\u001b[0m, in \u001b[0;36mEntityAgent.act\u001b[0;34m(self, action_spec)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_control_lock:\n\u001b[1;32m    146\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_phase(entity_component\u001b[38;5;241m.\u001b[39mPhase\u001b[38;5;241m.\u001b[39mPRE_ACT)\n\u001b[0;32m--> 147\u001b[0m   contexts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parallel_call_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpre_act\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_spec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context_processor\u001b[38;5;241m.\u001b[39mpre_act(types\u001b[38;5;241m.\u001b[39mMappingProxyType(contexts))\n\u001b[1;32m    149\u001b[0m   action_attempt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_act_component\u001b[38;5;241m.\u001b[39mget_action_attempt(\n\u001b[1;32m    150\u001b[0m       contexts, action_spec\n\u001b[1;32m    151\u001b[0m   )\n",
      "File \u001b[0;32m~/Projects/Autism-simulation/concordia/agents/entity_agent.py:139\u001b[0m, in \u001b[0;36mEntityAgent._parallel_call_\u001b[0;34m(self, method_name, *args)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the named method in parallel on all components.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03mAll calls will be issued with the same payloads.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m  the method call.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    135\u001b[0m tasks \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    136\u001b[0m     name: functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mgetattr\u001b[39m(component, method_name), \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, component \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context_components\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    138\u001b[0m }\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcurrency\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_tasks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Autism-simulation/concordia/utils/concurrency.py:126\u001b[0m, in \u001b[0;36mrun_tasks\u001b[0;34m(tasks, timeout, max_workers)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_tasks\u001b[39m(\n\u001b[1;32m    102\u001b[0m     tasks: Mapping[\u001b[38;5;28mstr\u001b[39m, Callable[[], _T]],\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    104\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    105\u001b[0m     max_workers: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Mapping[\u001b[38;5;28mstr\u001b[39m, _T]:\n\u001b[1;32m    107\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Runs the callables in parallel, blocks until first failure.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m  IMPORTANT: Passed callables must be threadsafe.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    Exception: If any task raises an exception.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m--> 126\u001b[0m       key: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m _as_completed(\n\u001b[1;32m    128\u001b[0m           tasks, timeout\u001b[38;5;241m=\u001b[39mtimeout, max_workers\u001b[38;5;241m=\u001b[39mmax_workers\n\u001b[1;32m    129\u001b[0m       )\n\u001b[1;32m    130\u001b[0m   }\n",
      "File \u001b[0;32m/opt/anaconda3/envs/NDA/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/NDA/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/NDA/lib/python3.12/concurrent/futures/thread.py:59\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/Projects/Autism-simulation/concordia/utils/concurrency.py:60\u001b[0m, in \u001b[0;36m_run_task\u001b[0;34m(key, fn)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns fn() and logs any error.\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m   logging\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError in task \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, key)\n",
      "File \u001b[0;32m~/Projects/Autism-simulation/examples/D2A/value_components/value_comp.py:522\u001b[0m, in \u001b[0;36mValueTracker.pre_act\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpre_act\u001b[39m(\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    519\u001b[0m     unused_action_spec: entity_lib\u001b[38;5;241m.\u001b[39mActionSpec,\n\u001b[1;32m    520\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m unused_action_spec\n\u001b[0;32m--> 522\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pre_act_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/Projects/Autism-simulation/concordia/components/agent/action_spec_ignored.py:71\u001b[0m, in \u001b[0;36mActionSpecIgnored.get_pre_act_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m     70\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_act_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_act_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_pre_act_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_act_value\n",
      "File \u001b[0;32m~/Projects/Autism-simulation/examples/D2A/value_components/value_comp.py:504\u001b[0m, in \u001b[0;36mValueTracker._make_pre_act_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_pre_act_value\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    503\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_counter\n\u001b[0;32m--> 504\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_track_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logging_channel({\n\u001b[1;32m    506\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m: index,\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindividual_desire_tracker\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_individual_desire_tracker[index],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindividual_qualitative_desire_tracker\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_individual_qualitative_desire_tracker[index]\n\u001b[1;32m    511\u001b[0m     })\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe value of the desire has been updated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Projects/Autism-simulation/examples/D2A/value_components/value_comp.py:481\u001b[0m, in \u001b[0;36mValueTracker._track_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    479\u001b[0m current_delta_tracker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m() \u001b[38;5;66;03m# track the delta of the desire\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m desire_component_name, desire_component \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_desire_components\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 481\u001b[0m     current_numerical_value \u001b[38;5;241m=\u001b[39m \u001b[43mdesire_component\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_current_numerical_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m     current_qualitative_value \u001b[38;5;241m=\u001b[39m desire_component\u001b[38;5;241m.\u001b[39mget_current_qualitative_value()\n\u001b[1;32m    483\u001b[0m     current_value_name \u001b[38;5;241m=\u001b[39m desire_component\u001b[38;5;241m.\u001b[39mget_desire_name()\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[0;32m~/Projects/Autism-simulation/examples/D2A/value_components/value_comp.py:326\u001b[0m, in \u001b[0;36mdesire.get_current_numerical_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_current_numerical_value\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pre_act_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# update the value of the desire\u001b[39;00m\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value)\n",
      "File \u001b[0;32m~/Projects/Autism-simulation/concordia/components/agent/action_spec_ignored.py:71\u001b[0m, in \u001b[0;36mActionSpecIgnored.get_pre_act_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m     70\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_act_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_act_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_pre_act_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pre_act_value\n",
      "File \u001b[0;32m~/Projects/Autism-simulation/examples/D2A/value_components/value_comp.py:291\u001b[0m, in \u001b[0;36mdesire._make_pre_act_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m     updated_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_value_from_action_and_observation(action_attempt, observation_value)\u001b[38;5;66;03m#################3\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# print(\"after update the value of the desire\")\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# end here\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# print(self._value_name, '\\n',updated_log)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# convert the numeric desire to qualitative desire\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# qualitative_desire, convert_numeric_prompt = self._convert_numeric_desire_to_qualitative()\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m qualitative_desire, convert_numeric_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_numeric_desire_to_qualitative_by_hard_coding\u001b[49m()\n\u001b[1;32m    292\u001b[0m converted_log \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconvert_numeric_prompt\u001b[39m\u001b[38;5;124m'\u001b[39m: convert_numeric_prompt,\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqualitative_desire\u001b[39m\u001b[38;5;124m'\u001b[39m: qualitative_desire\n\u001b[1;32m    295\u001b[0m }\n\u001b[1;32m    297\u001b[0m \u001b[38;5;66;03m# print(\"after convert the numeric desire to qualitative desire\")\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SenseOfSafetyAndAttachment' object has no attribute '_convert_numeric_desire_to_qualitative_by_hard_coding'"
     ]
    }
   ],
   "source": [
    "save_files = {}\n",
    "result = run_simulation()\n",
    "save_path = save_simulation_results(result, envs='preschool_simulation',)\n",
    "\n",
    "print(f\" Finished simulation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b91f68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
